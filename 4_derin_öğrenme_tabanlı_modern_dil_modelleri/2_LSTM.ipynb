{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8a8c64b",
   "metadata": {},
   "source": [
    "LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c060e7a",
   "metadata": {},
   "source": [
    "aşamalarımız:\\\n",
    "1- import libraries\\\n",
    "2- create dataset\\\n",
    "3- tokenizer and dizilerin hazırlanması\\\n",
    "4- metinleri sıralayalim ve padding işlemi uygulayalım\\\n",
    "5- crete LSTM model\\\n",
    "6- train LSTM model\\\n",
    "7- evaluation ve metin tamamlama calismasi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b186356d",
   "metadata": {},
   "source": [
    "amacımız: kelime girdiğinde devamını modleimizin getriemsini istiyoruz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4f5f978",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Embedding\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9330e0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "        \"Merhaba, nasılsınız? Ben oldukça iyiyim.\", \n",
    "        \"Spor yaparken enerjim artıyor ve kendimi iyi hissediyorum.\",\n",
    "        \"Bugün hava çok güzel, dışarıda yürüyüş yapmalıyım.\",\n",
    "        \"Akşam yemeği için ne pişireceğim konusunda kararsızım.\",\n",
    "        \"Yarın arkadaşlarımla buluşmaya gideceğim.\",\n",
    "        \"Kütüphaneye gidip yeni kitaplar almayı düşünüyorum.\",\n",
    "        \"İşim çok yoğun ama bu hafta sonu tatil yapmayı planlıyorum.\",\n",
    "        \"Kahvemi almayı unuttum, hemen bir fincan içmeliyim.\",\n",
    "        \"Bugün film izlemeyi çok istiyorum.\",\n",
    "        \"Sabah erken kalkıp güne dinç başlamak harika oldu.\",\n",
    "        \"Tatile çıkmaya karar verdik, çok heyecanlıyım.\",\n",
    "        \"Yaz tatilinde denize girmeyi dört gözle bekliyorum.\",\n",
    "        \"Yeni bir dil öğrenmeye başlamak istiyorum.\",\n",
    "        \"Bugün biraz meditasyon yapıp rahatlamak iyi olabilir.\",\n",
    "        \"Kışın soğuk havası beni biraz zorlıyor.\",\n",
    "        \"Dün akşam bir arkadaşım ile uzun uzun sohbet ettik.\",\n",
    "        \"Yeni bir telefon almak istiyorum, hangi model daha iyi?\",\n",
    "        \"Köpeğimle parka çıkıp biraz yürüyüş yapacağım.\",\n",
    "        \"Bugün biraz alışveriş yapıp eksik olan şeyleri alacağım.\",\n",
    "        \"Sinemaya gitmek çok eğlenceli olacak.\",\n",
    "        \"Ailemle hafta sonu yemek yemeyi planlıyoruz.\",\n",
    "        \"Yolda yürürken çok güzel çiçekler gördüm.\",\n",
    "        \"Evde biraz temizlik yapmam gerek.\",\n",
    "        \"Dün gece çok geç uyudum, biraz uykusuzum.\",\n",
    "        \"Yaz tatilinde tatile gitmek için birkaç planım var.\",\n",
    "        \"Kitap okumak benim için çok rahatlatıcı bir aktivite.\",\n",
    "        \"Bazen uzun yürüyüşler yapmak ruhumu dinlendiriyor.\",\n",
    "        \"Bugün çok çalıştım, biraz dinlenmeliyim.\",\n",
    "        \"Öğle yemeği için ne yesem acaba?\",\n",
    "        \"Arkadaşımın doğum günü partisinde çok eğlendim.\",\n",
    "        \"Yeni bir müzik aleti çalmayı öğrenmeye karar verdim.\",\n",
    "        \"Bugün pazara gitmek istiyorum, alışveriş yapmam gerekiyor.\",\n",
    "        \"Akşam yemeği için pizza yapmayı düşünüyorum.\",\n",
    "        \"Tatil için hazırlıklarımı yapmaya başladım.\",\n",
    "        \"Günlük alışkanlıklarımı düzene sokmaya karar verdim.\",\n",
    "        \"Bana biraz motivasyon lazım, bugün iyi bir gün olacak.\",\n",
    "        \"Gün sonunda biraz meditasyon yaparak rahatlamayı planlıyorum.\",\n",
    "        \"Bugün arkadaşım bana sürpriz yaptı, çok mutlu oldum.\",\n",
    "        \"Sabah kahvemi içmeden asla işe başlamam.\",\n",
    "        \"Bazen uzun yürüyüşler yapmak bana çok iyi geliyor.\",\n",
    "        \"Kitap okumak bana çok şey katıyor, her gün bir sayfa okumaya karar verdim.\",\n",
    "        \"Dışarıda rüzgar var ama yine de yürüyüş yapmayı planlıyorum.\",\n",
    "        \"Yeni bir telefon almak istiyorum, hangisini önerirsiniz?\",\n",
    "        \"Akşam film izlemek için güzel bir seçenek olabilir.\",\n",
    "        \"Daha fazla su içmem gerekiyor, bugün yeterince içmedim.\",\n",
    "        \"Bugün biraz yoga yapmayı düşünüyorum, rahatlamaya ihtiyacım var.\",\n",
    "        \"Bazen evde sakin bir ortamda sadece müzik dinlemek güzel oluyor.\",\n",
    "        \"Kendime yeni bir hedef belirledim, ona odaklanacağım.\",\n",
    "        \"Ailemle dışarıda güzel bir akşam yemeği yedik.\",\n",
    "        \"Bugün güne erken başladım ve verimli geçti.\",\n",
    "        \"Spor salonuna yazıldım, bu hafta başlıyorum.\",\n",
    "        \"Dışarıda yağmur yağıyor ama yine de dışarı çıkmak istiyorum.\",\n",
    "        \"Yeni bir hobi edinmeyi düşünüyorum.\",\n",
    "        \"Bugün bir arkadaşım bana çok güzel bir hediye verdi.\",\n",
    "        \"Her gün biraz yürüyüş yapmak istiyorum, sağlığım için önemli.\",\n",
    "        \"Dün akşam çok lezzetli bir yemek yaptım, tarifimi arkadaşlarıma vereceğim.\",\n",
    "        \"Bazen evde vakit geçirmek bana iyi geliyor.\",\n",
    "        \"Bugün arkadaşımın doğum günü, ona bir sürpriz hazırladım.\",\n",
    "        \"Akşam yemeği için makarna yapmayı planlıyorum.\",\n",
    "        \"Bugün işe gitmek zor ama hafta sonu tatil var.\",\n",
    "        \"Daha fazla egzersiz yapmalıyım, sağlığım için çok önemli.\",\n",
    "        \"Bu sabah çok enerjik hissettim, çok verimli bir gün oldu.\",\n",
    "        \"Arkadaşlarım bana bugün gerçekten güzel bir gün yaşattılar.\",\n",
    "        \"Bugün biraz alışveriş yapmalıyım, eksik şeyler var.\",\n",
    "        \"Kendime yeni bir kitap aldım, bu akşam okumayı düşünüyorum.\",\n",
    "        \"Evdeki her şey çok dağınık, biraz toparlamalıyım.\",\n",
    "        \"Bugün çok güzel bir sabah yürüyüşü yaptım.\",\n",
    "        \"Yarın sabah erken kalkıp kahvaltıya gideceğim.\",\n",
    "        \"Günümüzde teknoloji çok hızlı gelişiyor.\",\n",
    "        \"Birçok yeni şey öğrenmek istiyorum.\",\n",
    "        \"Çalışma masamı düzenlemem gerek, çok dağınık.\",\n",
    "        \"Evde dinlenmek çok iyi geliyor, özellikle hafta sonları.\",\n",
    "        \"Bugün hava biraz kapalı ama yine de dışarı çıkmalıyım.\",\n",
    "        \"Çok fazla çay içiyorum, biraz azaltmalıyım.\",\n",
    "        \"Bu akşam sinemaya gitmek istiyorum.\",\n",
    "        \"Arkadaşlarımla birlikte dışarıda bir etkinlik yapmayı düşünüyorum.\",\n",
    "        \"Bugün biraz sanat galerisi gezmeye karar verdim.\",\n",
    "        \"Birkaç hafta önce başladığım projeyi bitirmeliyim.\",\n",
    "        \"Çalışma odamı yeniden düzenleyeceğim.\",\n",
    "        \"Yaz tatilinde nereye gitmek istediğimi düşünüyorum.\",\n",
    "        \"Bazen dışarıda arkadaşlarla yürümek çok rahatlatıcı oluyor.\",\n",
    "        \"Evde yoga yapmayı çok seviyorum.\",\n",
    "        \"Bu hafta sonu bir tatile çıkmayı düşünüyorum.\",\n",
    "        \"Bugün spor salonuna üye oldum, artık daha fazla çalışacağım.\",\n",
    "        \"Dışarıda yürürken çok güzel manzaralar gördüm.\",\n",
    "        \"Günümü planlamak için biraz zaman ayırmalıyım.\",\n",
    "        \"Biraz müzik dinlemek bana gerçekten iyi geliyor.\",\n",
    "        \"Bugün fazla yürüdüm, biraz dinlenmem gerek.\",\n",
    "        \"Evde kaldığımda kitap okumak bana çok iyi geliyor.\",\n",
    "        \"Yemek yaparken yeni tarifler denemek çok eğlenceli.\",\n",
    "        \"Arkadaşım bu sabah benden yardım istedi.\",\n",
    "        \"Bu hafta sonu piknik yapmaya karar verdim.\",\n",
    "        \"Kendimi geliştirmek için online kurslara katılmayı planlıyorum.\",\n",
    "        \"Bugün çok güzel bir gün, kesinlikle dışarı çıkmalıyım.\",\n",
    "        \"Bazen hayatın tadını çıkarmak için yavaşlamak gerek.\",\n",
    "        \"Bugün çok işim vardı ama yine de çok mutlu oldum.\",\n",
    "        \"Herkesin sağlıklı kalması önemli, spor yapmayı ihmal etmemeliyiz.\",\n",
    "        \"Bu akşam yeni bir dizi izlemeye başlayacağım.\",\n",
    "        \"Kahvaltı yapmayı asla atlamam, güne enerjik başlamak için çok önemli.\",\n",
    "        \"Gün boyunca çok çalıştım ama sonunda güzel bir akşam yemeği hazırladım.\",\n",
    "        \"Dışarıda yağmur yağıyor ama hala yürüyüş yapmak istiyorum.\"\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9cdf361e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101\n"
     ]
    }
   ],
   "source": [
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24dc0609",
   "metadata": {},
   "source": [
    "3- tokenizer ve dizileirn hazirlanmasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dffa3393",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(texts)\n",
    "total_words = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124f1515",
   "metadata": {},
   "source": [
    "4- metin siralayalim ve padding islemi uygulayalim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4a55f558",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[118, 119],\n",
       " [118, 119, 120],\n",
       " [118, 119, 120, 121],\n",
       " [118, 119, 120, 121, 122],\n",
       " [32, 59],\n",
       " [32, 59, 123],\n",
       " [32, 59, 123, 124],\n",
       " [32, 59, 123, 124, 60],\n",
       " [32, 59, 123, 124, 60, 61],\n",
       " [32, 59, 123, 124, 60, 61, 10]]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sequences = []\n",
    "for text in texts:\n",
    "    token_list = tokenizer.texts_to_sequences([text])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "        input_sequences.append(n_gram_sequence)\n",
    "\n",
    "input_sequences[:10] # ilk 10 tane goster sayialrin her biri bir kelimeyi ifade ediyor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "30e7968c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_sequence_length = max(len(x) for x in input_sequences)\n",
    "max_sequence_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8381889d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0, ...,   0, 118, 119],\n",
       "       [  0,   0,   0, ..., 118, 119, 120],\n",
       "       [  0,   0,   0, ..., 119, 120, 121],\n",
       "       ...,\n",
       "       [  0,   0,   0, ...,  16, 325,  25],\n",
       "       [  0,   0,   0, ..., 325,  25,  38],\n",
       "       [  0,   0,   0, ...,  25,  38,   9]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sequences = pad_sequences(input_sequences, maxlen = max_sequence_length, padding = \"pre\")\n",
    "input_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2be80e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x :\n",
      "[[  0   0   0   0   0   0   0   0   0   0   0 118]\n",
      " [  0   0   0   0   0   0   0   0   0   0 118 119]\n",
      " [  0   0   0   0   0   0   0   0   0 118 119 120]\n",
      " [  0   0   0   0   0   0   0   0 118 119 120 121]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  32]]\n",
      "y (tahmni ediceimiz) :\n",
      "[119 120 121 122  59]\n"
     ]
    }
   ],
   "source": [
    "x, y = input_sequences[:,:-1], input_sequences[:, -1]\n",
    "# x mesela 1. satirda 1. sütundan sondan birinciye kadar olsun,\n",
    "# y ise 1. satirin son sütunu olsun\n",
    "# \"x\" ten \"y\" yi tahmin edicez yani\n",
    "print(\"x :\")\n",
    "print(x[:5])\n",
    "print(\"y (tahmni ediceimiz) :\")\n",
    "print(y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b85a8c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tf.keras.utils.to_categorical(y, num_classes = total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b63cd9d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14fb26a3",
   "metadata": {},
   "source": [
    "create LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "133eed6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(total_words, 50, input_length = x.shape[1]))\n",
    "model.add(LSTM(100, return_sequences = False))\n",
    "model.add(Dense(total_words, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9743f346",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01968309",
   "metadata": {},
   "source": [
    "train LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8f2e5751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 1.3513 - accuracy: 0.7801\n",
      "Epoch 2/60\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 1.3058 - accuracy: 0.7945\n",
      "Epoch 3/60\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 1.2532 - accuracy: 0.7978\n",
      "Epoch 4/60\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 1.2170 - accuracy: 0.8042\n",
      "Epoch 5/60\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 1.1802 - accuracy: 0.8074\n",
      "Epoch 6/60\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 1.1353 - accuracy: 0.8202\n",
      "Epoch 7/60\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 1.0992 - accuracy: 0.8202\n",
      "Epoch 8/60\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 1.0616 - accuracy: 0.8250\n",
      "Epoch 9/60\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 1.0217 - accuracy: 0.8283\n",
      "Epoch 10/60\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.9903 - accuracy: 0.8315\n",
      "Epoch 11/60\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.9522 - accuracy: 0.8379\n",
      "Epoch 12/60\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.9252 - accuracy: 0.8347\n",
      "Epoch 13/60\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.8948 - accuracy: 0.8379\n",
      "Epoch 14/60\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.8680 - accuracy: 0.8379\n",
      "Epoch 15/60\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.8450 - accuracy: 0.8443\n",
      "Epoch 16/60\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.8137 - accuracy: 0.8475\n",
      "Epoch 17/60\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.7910 - accuracy: 0.8411\n",
      "Epoch 18/60\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.7675 - accuracy: 0.8491\n",
      "Epoch 19/60\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.7459 - accuracy: 0.8571\n",
      "Epoch 20/60\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.7268 - accuracy: 0.8539\n",
      "Epoch 21/60\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.7043 - accuracy: 0.8539\n",
      "Epoch 22/60\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.6853 - accuracy: 0.8620\n",
      "Epoch 23/60\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 0.6676 - accuracy: 0.8620\n",
      "Epoch 24/60\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.6546 - accuracy: 0.8636\n",
      "Epoch 25/60\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.6337 - accuracy: 0.8684\n",
      "Epoch 26/60\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.6201 - accuracy: 0.8716\n",
      "Epoch 27/60\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.6075 - accuracy: 0.8732\n",
      "Epoch 28/60\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.5869 - accuracy: 0.8716\n",
      "Epoch 29/60\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 0.5713 - accuracy: 0.8780\n",
      "Epoch 30/60\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.5603 - accuracy: 0.8732\n",
      "Epoch 31/60\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 0.5470 - accuracy: 0.8764\n",
      "Epoch 32/60\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 0.5332 - accuracy: 0.8764\n",
      "Epoch 33/60\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 0.5281 - accuracy: 0.8732\n",
      "Epoch 34/60\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.5137 - accuracy: 0.8812\n",
      "Epoch 35/60\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 0.5026 - accuracy: 0.8764\n",
      "Epoch 36/60\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.4907 - accuracy: 0.8780\n",
      "Epoch 37/60\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 0.4817 - accuracy: 0.8876\n",
      "Epoch 38/60\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.4704 - accuracy: 0.8732\n",
      "Epoch 39/60\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.4660 - accuracy: 0.8909\n",
      "Epoch 40/60\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.4560 - accuracy: 0.8860\n",
      "Epoch 41/60\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.4461 - accuracy: 0.8812\n",
      "Epoch 42/60\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.4392 - accuracy: 0.8860\n",
      "Epoch 43/60\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.4339 - accuracy: 0.8876\n",
      "Epoch 44/60\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.4239 - accuracy: 0.8812\n",
      "Epoch 45/60\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.4172 - accuracy: 0.8892\n",
      "Epoch 46/60\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.4114 - accuracy: 0.8892\n",
      "Epoch 47/60\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 0.4046 - accuracy: 0.8973\n",
      "Epoch 48/60\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.3999 - accuracy: 0.8860\n",
      "Epoch 49/60\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.3953 - accuracy: 0.8909\n",
      "Epoch 50/60\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.3906 - accuracy: 0.8892\n",
      "Epoch 51/60\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.3848 - accuracy: 0.8812\n",
      "Epoch 52/60\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.3766 - accuracy: 0.8876\n",
      "Epoch 53/60\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.3770 - accuracy: 0.8828\n",
      "Epoch 54/60\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.3686 - accuracy: 0.8925\n",
      "Epoch 55/60\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.3643 - accuracy: 0.8812\n",
      "Epoch 56/60\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.3582 - accuracy: 0.8844\n",
      "Epoch 57/60\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.3557 - accuracy: 0.8876\n",
      "Epoch 58/60\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 0.3514 - accuracy: 0.8909\n",
      "Epoch 59/60\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.3472 - accuracy: 0.8941\n",
      "Epoch 60/60\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.3440 - accuracy: 0.8989\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x204143ea410>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y, epochs = 60, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c104a036",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_word(seed_text, next_word):\n",
    "    for _ in range(next_word):\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen = max_sequence_length-1, padding = \"pre\")\n",
    "        predicted_probs = model.predict(token_list, verbose = 0) # tüm y lerden hepsiinn olma olasiliğini çıakrdı\n",
    "        predicted_word_inndex = np.argmax(predicted_probs, axis = -1) # tüm olasiliktan en yükselk olanı seçti\n",
    "        predicted_word = tokenizer.index_word[predicted_word_inndex[0]] # en yüskke olasilikli oalnı yazdırdı\n",
    "        seed_text = seed_text + \" \" + predicted_word # buraya da ekledi\n",
    "    \n",
    "    return seed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "110d3ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yarın burada arkadaşlarımla\n",
      "Yarın burada arkadaşlarımla buluşmaya gideceğim\n",
      "Yarın burada arkadaşlarımla buluşmaya gideceğim gideceğim yavaşlamak gerek çok önemli var var\n"
     ]
    }
   ],
   "source": [
    "seed_text = \"Yarın burada\"\n",
    "print(predict_next_word(seed_text, 1))\n",
    "print(predict_next_word(seed_text, 3))\n",
    "print(predict_next_word(seed_text, 10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
